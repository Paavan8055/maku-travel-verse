"""
mem_service.py
================

This module provides a thin wrapper around the Mem0 Python SDK for storing
and retrieving conversational memory in a ChatGPT‑based application.  It
encapsulates initialisation of the Mem0 client using an API key and offers
a single function (`chat_with_memory`) that proxies calls to OpenAI via
Mem0, storing user preferences and returning context‑aware completions.

Before using this module, set the ``MEM0_API_KEY`` environment variable
to your project’s Mem0 API key.  This key can be generated from the
Mem0 dashboard for the relevant organisation and project.

Usage Example::

    from mem_service import chat_with_memory

    # Compose a chat message history
    messages = [
        {"role": "user", "content": "I love Indian food but can't eat cheese."}
    ]
    user_id = "alice"
    reply = chat_with_memory(user_id=user_id, messages=messages)
    print(reply)

This will store the dietary preference in Mem0 and tailor subsequent
recommendations based on the retrieved memory.

Note: Additional parameters such as ``agent_id`` or ``metadata`` can be
provided to the underlying Mem0 API as needed.  See the Mem0
documentation for details.
"""

import os
from typing import List, Dict, Any

from mem0.proxy.main import Mem0


def _get_client() -> Mem0:
    """Initialise and return a Mem0 client using the API key.

    The API key must be provided via the ``MEM0_API_KEY`` environment
    variable.  If the key is not set, a ``RuntimeError`` is raised.
    """
    api_key = os.environ.get("MEM0_API_KEY")
    if not api_key:
        raise RuntimeError(
            "MEM0_API_KEY environment variable is not set. Please define it "
            "with your Mem0 project API key before using the mem_service."
        )
    return Mem0(api_key=api_key)


def chat_with_memory(
    *,
    user_id: str,
    messages: List[Dict[str, str]],
    model: str = "gpt-4o",
    agent_id: str | None = None,
    metadata: Dict[str, Any] | None = None,
    filters: Dict[str, Any] | None = None,
    limit: int | None = None,
) -> str:
    """Send a chat completion request via Mem0 and return the assistant's reply.

    Parameters
    ----------
    user_id : str
        A unique identifier for the end user.  Memories are scoped to this ID.
    messages : List[Dict[str, str]]
        A list of chat messages where each element is a dictionary with
        ``role`` and ``content`` keys, matching the OpenAI API format.
    model : str, optional
        The name of the model to use (default is ``"gpt-4o"``).  Any
        OpenAI-compatible model supported by Mem0 may be used.
    agent_id : str | None, optional
        Optional identifier for the agent.  Useful when multiple agents share
        the same underlying memory.
    metadata : dict | None, optional
        Additional metadata to store alongside the memory.  For example,
        ``{"source": "website"}`` or ``{"source": "github"}``.
    filters : dict | None, optional
        Memory filters used when retrieving past memories.  Keys should
        correspond to metadata fields.
    limit : int | None, optional
        Maximum number of relevant memories to retrieve.  If ``None``,
        Mem0’s default (usually 10) is used.

    Returns
    -------
    str
        The assistant's reply generated by the model, enriched with
        retrieved memories.
    """
    client = _get_client()
    # Build parameters for the chat completion call
    params: Dict[str, Any] = {
        "messages": messages,
        "model": model,
        "user_id": user_id,
    }
    if agent_id:
        params["agent_id"] = agent_id
    if metadata:
        params["metadata"] = metadata
    if filters:
        params["filters"] = filters
    if limit is not None:
        params["limit"] = limit

    # Make the request via Mem0
    response = client.chat.completions.create(**params)
    # Extract and return the assistant's message
    return response.choices[0].message.content


__all__ = ["chat_with_memory"]
